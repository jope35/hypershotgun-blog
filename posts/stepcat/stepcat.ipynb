{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"baby steps: tuneing big model one step at a time\"\n",
    "author: \"Joost de Theije + LLM\"\n",
    "subtitle: \"stepwise tuning of gradient boosting models\"\n",
    "date: \"03/14/2024\"\n",
    "image: \"\"\n",
    "abstract: \"\"\n",
    "format:\n",
    "  html: default\n",
    "draft: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hello world ðŸ‘‹ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = 1240\n",
    "X, y = fetch_openml(data_id=ID, data_home=f\"openml_download_{ID}\", return_X_y=True)\n",
    "\n",
    "X = X.sample(frac=0.2)\n",
    "X = X.dropna(axis=0, how=\"any\")\n",
    "y = y.loc[X.index]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = CatBoostClassifier(\n",
    "    iterations=32,\n",
    "    loss_function=\"Logloss\",\n",
    "    eval_metric=\"F1\",\n",
    "    metric_period=16,\n",
    "    cat_features=list(X.select_dtypes(include=\"category\").columns),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x10b87b2b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(\n",
    "    X_train, y_train, eval_set=(X_test, y_test), metric_period=16, verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8007828136814482"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.get_best_score().get(\"validation\").get(\"F1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tree parameters\n",
    "    * Depth\n",
    "    * min_data_in_leaf\n",
    "    * grow_policy\n",
    "2. Sampling parameters\n",
    "    * Subsample\n",
    "    * colsample_bylevel\n",
    "    * sampling_frquency\n",
    "3. Regularization parameters\n",
    "    * penalties_coefficient\n",
    "    * first_feature_use_penalties\n",
    "    * leaf_estimation_backtracking\n",
    "4. Learning rate\n",
    "    * Iterations\n",
    "    * learning_rate\n",
    "    * model_shrink_rate\n",
    "    * boost_from_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- what are hyperparams, and why tune\n",
    "- gridsearch, randomsearch, lhs search -> pro cons of each\n",
    "- optuna in one go\n",
    "- optuna in steps \n",
    "- compare time should be less, for same or better performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 15),\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 8, 128),\n",
    "    }\n",
    "\n",
    "    cbc = CatBoostClassifier(\n",
    "        **param,\n",
    "        eval_metric=\"F1\",\n",
    "        cat_features=list(X.select_dtypes(include=\"category\").columns),\n",
    "    )\n",
    "    cbc.fit(\n",
    "        X_train, y_train, eval_set=(X_test, y_test), metric_period=16, verbose=False\n",
    "    )\n",
    "\n",
    "    return cbc.get_best_score().get(\"validation\").get(\"F1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-21 22:54:51,897] A new study created in memory with name: no-name-314011ed-0df5-4293-9531-d61007dad81e\n",
      "[I 2024-03-21 22:55:04,378] Trial 0 finished with value: 0.8108783857879154 and parameters: {'depth': 12, 'iterations': 99}. Best is trial 0 with value: 0.8108783857879154.\n",
      "[I 2024-03-21 22:55:06,886] Trial 1 finished with value: 0.768937097172629 and parameters: {'depth': 1, 'iterations': 113}. Best is trial 0 with value: 0.8108783857879154.\n",
      "[I 2024-03-21 22:55:10,298] Trial 2 finished with value: 0.796464479063087 and parameters: {'depth': 2, 'iterations': 124}. Best is trial 0 with value: 0.8108783857879154.\n",
      "[I 2024-03-21 22:55:11,856] Trial 3 finished with value: 0.7971442639094042 and parameters: {'depth': 11, 'iterations': 16}. Best is trial 0 with value: 0.8108783857879154.\n",
      "[I 2024-03-21 22:55:21,657] Trial 4 finished with value: 0.8099571266077522 and parameters: {'depth': 12, 'iterations': 83}. Best is trial 0 with value: 0.8108783857879154.\n",
      "[I 2024-03-21 22:55:25,516] Trial 5 finished with value: 0.7995272500222995 and parameters: {'depth': 3, 'iterations': 126}. Best is trial 0 with value: 0.8108783857879154.\n",
      "[I 2024-03-21 22:55:27,284] Trial 6 finished with value: 0.8023090586145648 and parameters: {'depth': 6, 'iterations': 38}. Best is trial 0 with value: 0.8108783857879154.\n",
      "[I 2024-03-21 22:55:29,007] Trial 7 finished with value: 0.7947800182299193 and parameters: {'depth': 3, 'iterations': 54}. Best is trial 0 with value: 0.8108783857879154.\n",
      "[I 2024-03-21 22:56:05,942] Trial 8 finished with value: 0.8076261779876813 and parameters: {'depth': 15, 'iterations': 70}. Best is trial 0 with value: 0.8108783857879154.\n",
      "[I 2024-03-21 22:56:09,629] Trial 9 finished with value: 0.7996608581182089 and parameters: {'depth': 3, 'iterations': 115}. Best is trial 0 with value: 0.8108783857879154.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10, timeout=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj(trial, step):\n",
    "    all_step_param = {\n",
    "        1: {\n",
    "            \"depth\": trial.suggest_int(name=\"depth\", low=1, high=15),\n",
    "            \"iterations\": trial.suggest_int(\"iterations\", 8, 128),\n",
    "        },\n",
    "        2: {\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.01, 1.0),\n",
    "            \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 1.0),\n",
    "        },\n",
    "        3: {\n",
    "            \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
    "            \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.01, 1),\n",
    "        },\n",
    "        4: {\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    cbc = CatBoostClassifier(\n",
    "        **all_step_param[step],\n",
    "        eval_metric=\"F1\",\n",
    "        cat_features=list(X.select_dtypes(include=\"category\").columns),\n",
    "    )\n",
    "    cbc.fit(\n",
    "        X_train, y_train, eval_set=(X_test, y_test), metric_period=16, verbose=False\n",
    "    )\n",
    "\n",
    "    return cbc.get_best_score().get(\"validation\").get(\"F1\")\n",
    "\n",
    "\n",
    "def get_obj_step(step: int):\n",
    "    return partial(obj, step=step)\n",
    "\n",
    "\n",
    "# TODO feed to previous best params forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(get_obj_step(step), n_trials=10, timeout=120)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypershotgun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
