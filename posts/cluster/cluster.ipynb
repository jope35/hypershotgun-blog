{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Cluster\"\n",
    "author: \"Joost de Theije + LLM\"\n",
    "subtitle: \"together\"\n",
    "date: \"2024-01-17\"\n",
    "image: \"artifacts/clumper.gif\"\n",
    "abstract: \" \" # hack to display no text in the listing page\n",
    "format:\n",
    "  html: default\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TLDR;\n",
    "\n",
    "- **Unsupervised Learning** -> Clustering algorithms are used for unsupervised learning, ideal for exploratory data analysis.\n",
    "- **Grouping Data** -> These algorithms group similar data into clusters based on specific criteria.\n",
    "- **Variety of Applications** -> They're used in diverse fields like customer segmentation, anomaly detection, and more.\n",
    "- **Different Techniques** -> Various types exist, like K-means and DBSCAN, each with unique strengths and suited for specific data types.\n",
    "- **Choice of Parameters** -> The selection and tuning of parameters, like the number of clusters, significantly influence the results.\n",
    "\n",
    "In the field of machine learning,clustering algorithms play a role in uncovering hidden patterns present in the data. they group together datapoints based on the simalirty of features without the need for labeled data, these groups are refered to as clusters.\n",
    "There are multiple algorithms that can be used to perform cluster analysis.\n",
    "\n",
    "- centroid based (K-means)\n",
    "- connectivity-based aka hierarchical clustering (Agglomerative lcustering)\n",
    "- distribution based (Gaussian-mixture modelling)\n",
    "- density based (DBSCAN)\n",
    "\n",
    "Clustering algorithms have found their place in a diverse range of real-world applications, from customer segmentation in marketing strategies to image segmentation in computer vision, and anomaly detection in cybersecurity for insightful data-driven decision making.\n",
    "\n",
    "To demonstrate the workflow, I will use a K-means clustering algorithm to group together similar shoppers at a shopping mall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem Introduction\n",
    "\n",
    "As the owners of a thriving supermarket mall, you seek a deeper understanding of your customer base. Data points including demographics, spending habits, and loyalty program membership details are at your disposal. Your goal is to identify distinct groups within your customers to tailor marketing initiatives, thereby maximizing the efficiency of your promotional efforts.\n",
    "\n",
    "To achieve this, you opt for clustering algorithms to group similar customers based on characteristics and behaviors. By isolating specific segments of your customer base, you aim to tailor marketing strategies to respective subgroups, increasing the likelihood of a successful outcome and resulting in maximizing the bang for your marketing buck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![a lovely shopping mall ](/posts/cluster/artifacts/sung-jin-cho-BbVGAjfAQ4o-unsplash.jpg)\n",
    "\n",
    "\n",
    "Photo by <a href=\"https://unsplash.com/@mbuff?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash\">Sung Jin Cho</a> on <a href=\"https://unsplash.com/photos/people-walking-inside-white-building-BbVGAjfAQ4o?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash\">Unsplash</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "In this initial stage, the goal is to prepare the data for analysis. This involves cleaning the data by removing or filling in missing values, which could be done through various strategies like dropping the missing rows, filling them with mean/median/mode, or using a prediction model. It's also crucial to handle outliers and potentially normalize features if they're on different scales. This stage might also involve dealing with categorical variables using encoding techniques. Effective preprocessing is crucial for reliable results in the subsequent stages.\n",
    "\n",
    "\n",
    "the owner of the mall has provide the following [dataset](https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python)\n",
    "\n",
    "| Field                  | Description                                                               |\n",
    "| ---------------------- | ------------------------------------------------------------------------- |\n",
    "| CustomerID             | Unique ID assigned to the customer                                        |\n",
    "| Gender                 | Gender of the customer                                                    |\n",
    "| Age                    | Age of the customer                                                       |\n",
    "| Annual Income (k$)     | Annual income of the customer                                             |\n",
    "| Spending Score (1-100) | Score assigned by the mall based on customer behavior and spending nature |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import umap\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import power_transform\n",
    "from yellowbrick.cluster import kelbow_visualizer, silhouette_visualizer\n",
    "\n",
    "# setting global plotting settings\n",
    "# set_matplotlib_formats(\"svg\")\n",
    "sns.set_palette(\"tab10\")\n",
    "sns.set_style(\"darkgrid\")\n",
    "FIGSIZE = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: show\n",
    "\n",
    "\n",
    "# Load the customer dataset to analyze shopping patterns\n",
    "df_mall = pd.read_csv(\"artifacts/Mall_Customers.csv\")\n",
    "\n",
    "# rename columns to be lowercase, for easy typing\n",
    "df_mall = df_mall.rename(\n",
    "    columns={\n",
    "        \"CustomerID \": \"id\",\n",
    "        \"Gender \": \"gender\",\n",
    "        \"Age \": \"age\",\n",
    "        \"Annual Income (k$) \": \"income\",\n",
    "        \"Spending Score (1-100)\": \"spending\",\n",
    "    }\n",
    ")\n",
    "df_mall[\"gender\"] = df_mall[\"gender\"].str.lower()\n",
    "df_mall[\"gender\"] = df_mall[\"gender\"].str.strip()\n",
    "\n",
    "\n",
    "#\n",
    "print(f\"amount of NULL \\n{df_mall.isna().sum()} \\n\")\n",
    "\n",
    "# look at a random sample to validate the contents\n",
    "df_mall.sample(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, upon taking a look at the dataset, it seems like we've got a mix of numeric and non-numeric columns. Specifically, the `gender` column is the only non-numeric feature - it's all categorical data, with customers labeled as either \"Male\" or \"Female\". All the other columns - `id`, `age`, `income`, and `spending` - are numeric data types.\n",
    "\n",
    "The `id` column looks like it's just a unique identifier for each customer, so we can exclude that one from our feature set for clustering. Makes sense, right?\n",
    "\n",
    "Now, the other features need to be in the same ballpark (i.e., normalized) to work effectively with clustering algorithms. Otherwise, the algorithm will group together instances based on the features with the highest numbers, rather than looking at all the features. That'd be like trying to compare apples and oranges!\n",
    "\n",
    "So, we need to process the `gender` column by encoding those categories as numbers. One common way to do this is to map \"Male\" and \"Female\" to 1 and 0, respectively. Once we've done that, gender will be represented numerically like the other features.\n",
    "\n",
    "In a nutshell, we need to encode the gender categorical data, exclude the customer `id` column, and normalize the remaining columns before we can apply clustering algorithms. Luckily for us, there are no NULL values in the data, so we don't have to worry about dealing with those. Easy peasy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: show\n",
    "\n",
    "# convert gender to a numerical value via one-hot-encoding\n",
    "# clustering models usally need numerical values\n",
    "df_mall = df_mall.assign(gender=df_mall[\"gender\"].map({\"male\": 1, \"female\": 0}))\n",
    "\n",
    "# list with features for easy reference\n",
    "features = [\"age\", \"income\", \"spending\", \"gender\"]\n",
    "df_feature = df_mall[features]\n",
    "\n",
    "\n",
    "# look at a random sample to validate the contents\n",
    "df_feature.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used one-hot encoding to convert the string values of the gender column into numerical values, using the pandas map method in combination with a simple mapping of \"male\" to 1 and \"female\" to 0. This resulted in a new \"gender\" column with 0/1 encoding.\n",
    "The `id` column is dropped from the feature dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "In this section, we visualize the data and hope to gain some insights into meaningful patterns that can inform our clustering analysis during the next phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_feature.describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains information 200 customers. The average (mean) age is 38.85 years. Ages range from 18 to 70, with 50% of customers aged 36 years or below.\n",
    "\n",
    "The average annual income is $60,560, ranging from $15,000 to $137,000. 50% of customers earn $61,500 or less.\n",
    "\n",
    "For the spending score (1-100), the average is 50.2. Half the customers have a spending score of 50 or below. The minimum is 1 and maximum 99, showing a wide range in spending habits.\n",
    "\n",
    "Overall, we see variation among customers in age, income levels, and purchasing patterns. Clustering algorithms can help segment customers into groups based on these attributes to develop targeted marketing approaches. let us first look at the distributions of the features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: show\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=FIGSIZE)\n",
    "\n",
    "curr_ax = ax[0]\n",
    "sns.countplot(data=df_feature, x=\"gender\", stat=\"count\", hue=\"gender\", ax=curr_ax)\n",
    "curr_ax.legend([\"female\", \"male\"])\n",
    "# little hacky way of getting the numbers to show in the plot\n",
    "curr_ax.bar_label(curr_ax.containers[0], fontsize=10)\n",
    "curr_ax.bar_label(curr_ax.containers[1], fontsize=10)\n",
    "\n",
    "curr_ax = ax[1]\n",
    "sns.kdeplot(x=\"age\", data=df_feature, common_norm=False, hue=\"gender\", ax=curr_ax)\n",
    "curr_ax.legend([\"male\", \"female\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the barplot on the right shows the distribution between the gender. Our dataset contains more females(112) than males(88).\n",
    "\n",
    "now if we focus on the age distributions as shown in the kernel density estimation plots. The most striking observation here is that for both genders, there's a noticeable peak around 30 years of age. But, if you look closely, there seems to be a more significant number of men falling into the older age groups (55+)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=FIGSIZE)\n",
    "\n",
    "curr_ax = ax[0]\n",
    "sns.regplot(\n",
    "    data=df_feature[df_feature[\"gender\"] == 0],\n",
    "    x=\"age\",\n",
    "    y=\"income\",\n",
    "    color=sns.color_palette()[0],\n",
    "    order=1,\n",
    "    lowess=True,\n",
    "    truncate=True,\n",
    "    ax=curr_ax,\n",
    ")\n",
    "\n",
    "\n",
    "curr_ax = ax[0]\n",
    "sns.regplot(\n",
    "    data=df_feature[df_feature[\"gender\"] == 1],\n",
    "    x=\"age\",\n",
    "    y=\"income\",\n",
    "    color=sns.color_palette()[1],\n",
    "    order=1,\n",
    "    lowess=True,\n",
    "    truncate=True,\n",
    "    ax=curr_ax,\n",
    ")\n",
    "curr_ax.legend([\"gender=0\", \"lowess regression\", \"gender=1\", \"lowess regression\"])\n",
    "curr_ax.set_title(\"age vs. income\")\n",
    "\n",
    "\n",
    "curr_ax = ax[1]\n",
    "sns.regplot(\n",
    "    data=df_feature[df_feature[\"gender\"] == 0],\n",
    "    x=\"age\",\n",
    "    y=\"spending\",\n",
    "    color=sns.color_palette()[0],\n",
    "    order=1,\n",
    "    lowess=True,\n",
    "    truncate=True,\n",
    "    ax=curr_ax,\n",
    ")\n",
    "\n",
    "\n",
    "curr_ax = ax[1]\n",
    "sns.regplot(\n",
    "    data=df_feature[df_feature[\"gender\"] == 1],\n",
    "    x=\"age\",\n",
    "    y=\"spending\",\n",
    "    color=sns.color_palette()[1],\n",
    "    order=1,\n",
    "    lowess=True,\n",
    "    truncate=True,\n",
    "    ax=curr_ax,\n",
    ")\n",
    "curr_ax.legend([\"gender=0\", \"lowess regression\", \"gender=1\", \"lowess regression\"])\n",
    "curr_ax.set_title(\"age vs. spending\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the relation between age, income, and spending is an intriguing aspect of our dataset. using a scatterplot with a [lowess regression](https://en.wikipedia.org/wiki/Local_regression).\n",
    "\n",
    "starting with the left scatterplot we can see a postive correaltion between age and income up until 35 years old, with the income tapering off got older individuals. This finding is in line with our intuition â€“ as people age, they typically accumulate more income due to career advancement and increased earning potential. Interestingly, this trend appears to be consistent for both genders.\n",
    "\n",
    "However, the spending pattern is a different story! Up until 30 years of age, we see a slight increase in spending. But around that age, there's a noticeable decrease in spending that lasts until approximately 50 years old. After that point, there's a slight uptick in spending again, but it doesn't quite reach the previous level. These findings suggest that people tend to spend less as they get older.\n",
    "\n",
    "The difference between genders regarding age and spending appears to be relatively small compared to the overall age effect. This means that both males and females exhibit similar trends in spending throughout their lives, with some differences in the exact shapes of their spending curves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=FIGSIZE)\n",
    "\n",
    "curr_ax = ax[0]\n",
    "sns.scatterplot(\n",
    "    data=df_feature,\n",
    "    x=\"income\",\n",
    "    y=\"spending\",\n",
    "    hue=\"age\",\n",
    "    palette=sns.color_palette(\"viridis\", as_cmap=True),\n",
    "    ax=curr_ax,\n",
    ")\n",
    "curr_ax.set_title(\"age\")\n",
    "\n",
    "\n",
    "curr_ax = ax[1]\n",
    "sns.scatterplot(\n",
    "    data=df_feature,\n",
    "    x=\"income\",\n",
    "    y=\"spending\",\n",
    "    hue=\"gender\",\n",
    "    ax=curr_ax,\n",
    ")\n",
    "curr_ax.set_title(\"gender\")\n",
    "curr_ax.legend([\"female\", \"male\"])\n",
    "\n",
    "plt.suptitle(\"the relation between income and spending\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the left scatterplot you can clearly see that younger people do seem to have higher levels of spending, but as we move towards older age groups, the spending levels decrease for most individuals. There is no clear relation between income and spending. The cluster of people with spending and income in the 40-60 and 40-65 ranges could indicate that these individuals are in a specific life stage, such as starting families or paying off mortgages. Alternatively, it might suggest that there's an external factor influencing both income and spending for this group.\n",
    "\n",
    "Regarding the right scatterplot, it seems that there's no apparent relationship between income/spending and gender, as the colors representing males and females appear to be evenly distributed throughout the plot. This suggests that income and spending levels are relatively similar for both genders in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a ratio between income and spending\n",
    "df_ratio = df_feature.assign(si_ratio=df_feature[\"income\"] / df_feature[\"spending\"])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=FIGSIZE)\n",
    "curr_ax = ax[0]\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_ratio,\n",
    "    x=\"si_ratio\",\n",
    "    y=\"age\",\n",
    "    hue=\"gender\",\n",
    "    alpha=0.7,\n",
    "    ax=curr_ax,\n",
    ")\n",
    "curr_ax.legend([\"male\", \"female\"])\n",
    "curr_ax.set_title(\"income / spending - unclipped\")\n",
    "\n",
    "# clip to 95% quantile of the si ratio,\n",
    "# this will zoom into the interesting part of the plot\n",
    "df_ratio = df_ratio.assign(\n",
    "    si_ratio_clip=df_ratio[\"si_ratio\"].clip(\n",
    "        upper=np.quantile(df_ratio[\"si_ratio\"], 0.95)\n",
    "    )\n",
    ")\n",
    "\n",
    "curr_ax = ax[1]\n",
    "sns.scatterplot(\n",
    "    data=df_ratio,\n",
    "    x=\"si_ratio_clip\",\n",
    "    y=\"age\",\n",
    "    hue=\"gender\",\n",
    "    alpha=0.7,\n",
    "    ax=curr_ax,\n",
    ")\n",
    "curr_ax.set_xlim(right=np.ceil(np.quantile(df_ratio[\"si_ratio\"], 0.95)))\n",
    "curr_ax.legend([\"male\", \"female\"])\n",
    "curr_ax.set_title(\n",
    "    f\"income / spending - clipped @ {np.quantile(df_ratio['si_ratio'], 0.95):.2f}\"\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calculating the ratio of income to spending (i.e., income divided by spending), we can gain a better understanding of an individual's spending habits in relation to their income. The raw numbers alone don't provide a complete picture, but examining the relationship between these ratios can give us valuable insights. \n",
    "\n",
    "in the left plot, there are some outliers with rations around 80!!! that means that their income is much higher than the spending score that was assigned to them, possible cause could be a data entry error. To better visualize the trends in our data while still showing the majority of the data points, we can compress the rest of the data by [clipping](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.clip.html#pandas.DataFrame.clip) the values at the 0.95 quantile. This approach will help us to focus on the more typical spending behaviors.\n",
    "\n",
    "The right plot shows a clearer separation between age groups, with younger people generally having ratios below 1 and older people above 1 . Lower ratios indicate that individuals are spending relatively more than their income levels compared to their peers. Conversely, higher ratios suggest that they're spending less than their income levels.\n",
    "\n",
    "These findings could be due to various factors such as different life stages (e.g., younger people might have more debt or be starting families), savings goals, or lifestyle choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: show\n",
    "\n",
    "# apply yeo-johnson transform to si_ratio\n",
    "# this will make the data more like a normal distributuon\n",
    "df_ratio = df_ratio.assign(\n",
    "    si_ratio_transform=power_transform(\n",
    "        df_ratio[\"si_ratio\"].to_numpy().reshape(-1, 1), method=\"yeo-johnson\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=FIGSIZE)\n",
    "\n",
    "curr_ax = ax[0]\n",
    "sns.histplot(data=df_ratio[\"si_ratio\"], stat=\"percent\", ax=curr_ax)\n",
    "curr_ax.set_title(\"Original\")\n",
    "\n",
    "curr_ax = ax[1]\n",
    "sns.histplot(\n",
    "    data=df_ratio[\"si_ratio_transform\"],\n",
    "    stat=\"percent\",\n",
    "    ax=curr_ax,\n",
    ")\n",
    "curr_ax.set_title(\"applied Yeo-Johnson transform\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when using distance-based clustering algorithms like K-Means, it's essential to ensure that all features are on a comparable scale to avoid the algorithm being influenced disproportionately by one feature with larger values. The Yeo-Johnson power transformation is a popular method for normalizing data distribution, especially when dealing with skewed data like in our case. This transformation can help bring our income/spending ratio data closer to a more normal distribution, making it easier for clustering algorithms to identify meaningful patterns across all features. In the right plot, you can see how the [yeo-johnson](https://en.wikipedia.org/wiki/Power_transform#Yeo%E2%80%93Johnson_transformation) power transformation has helped to make the feature behave much more similarly to a normally distributed one, which will be beneficial when applying distance-based clustering algorithms. By ensuring that all features are on a comparable scale, we can effectively capture the relationships between income, spending, and potentially other demographic variables to discover meaningful patterns in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the EDA phase, we've observed a connection between age and spending/income. However, what constitutes high spending for a 20-year-old isn't the same as for a 60-year-old. To account for this, I've grouped ages into bins and calculated the difference between each bin's mean value and individual observations. The result is a number that shows whether someone spends more or less than average for their age bracket. Similarly, I applied this methodology to gender as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: show\n",
    "\n",
    "# bin the age variable into 7 bins\n",
    "# fmt: off\n",
    "binned = pd.cut(\n",
    "    df_feature[\"age\"],\n",
    "    bins=[0,20,30,40,50,60,70,80],\n",
    "    labels=[1,2,3,4,5,6,7],\n",
    "    )\n",
    "# fmt: on\n",
    "df_feature = df_feature.assign(age_bin=binned)\n",
    "\n",
    "# turn off the formatter, to increase readability\n",
    "# fmt: off\n",
    "# create a new column with the difference between income and the mean income of the gender group\n",
    "df_feature = df_feature.assign(\n",
    "    # create a new column with the difference between income and the mean income of the gender group\n",
    "    income_vs_gender_mean=df_feature['income'] - df_feature.groupby(\"gender\",)[[\"income\",]].transform(\"mean\").iloc[:, 0],\n",
    "    spending_vs_gender_mean=df_feature[\"spending\"] - df_feature.groupby(\"gender\")[[\"spending\",]].transform(\"mean\").iloc[:, 0],\n",
    "\n",
    "    # create a new column with the difference between income and the mean income of the age group\n",
    "    income_vs_age_mean=df_feature[\"income\"] - df_feature.groupby(\"age_bin\",observed=False)[[\"income\",]].transform(\"mean\").iloc[:, 0],\n",
    "    spending_vs_age_mean=df_feature[\"spending\"] - df_feature.groupby(\"age_bin\",observed=False)[[\"spending\",]].transform(\"mean\").iloc[:, 0],\n",
    ")\n",
    "# fmt: on\n",
    "\n",
    "df_feature.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To capture if a person is spending behaviour is deviating from what we might expect based on their incomer or age. to quantify this, i have opted to calculate the ratio between income (or age) and spending for each observation. this allows us to determine the young spenders or the old savers. at this stage no clipping or normalziation of the ratios is applied. that means that extreme values will be reflected in the data as they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: show\n",
    "\n",
    "# calculate the ratio between\n",
    "# spending and income -> how much of the income do you spend\n",
    "# spending and age -> if you are older do you spend more or less\n",
    "df_feature = df_feature.assign(\n",
    "    si_ratio=df_feature[\"income\"] / df_feature[\"spending\"],\n",
    "    sa_ratio=df_feature[\"age\"] / df_feature[\"spending\"],\n",
    ")\n",
    "df_feature.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now that we have all our features it is time to apply a power transform to them, By applying the Yeo-Johnson normalization method to each of your input features, you're transforming them in such a way that they approach normality, making the subsequent clustering process more reliable and robust. This transformation also ensures that all features contribute equally to the clustering results, as no single feature with high values will skew or distort the final outcomes, all will contribute in a fair manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# casting values to integer in order for scaling later on\n",
    "df_feature = df_feature.assign(\n",
    "    age_bin=df_feature[\"age_bin\"].astype(int),\n",
    ")\n",
    "\n",
    "df_feature[df_feature.select_dtypes(include=\"number\").columns] = power_transform(\n",
    "    X=df_feature[df_feature.select_dtypes(include=\"number\").columns],\n",
    "    method=\"yeo-johnson\",\n",
    ")\n",
    "df_feature.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values in the mean column are nearly zero, with a standard deviation of 1. Given these descriptive statistics and the data transformation we performed, we can be confident that the original data approximates a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "Use a suitable clustering algorithm (like K-means or hierarchical clustering) to divide customers into distinct groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "\n",
    "_ = kelbow_visualizer(\n",
    "    KMeans(\n",
    "        n_init=10,\n",
    "    ),\n",
    "    X=df_feature,\n",
    "    timings=False,\n",
    "    metric=\"distortion\",\n",
    "    ax=ax,\n",
    ")  # distortion: mean sum of squared distances to centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit kmeans for various number of clusters\n",
    "kmeans_clusters = [\n",
    "    KMeans(n_clusters=i, n_init=\"auto\", max_iter=900) for i in range(2, 11)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(18, 16), layout=\"constrained\")\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    silhouette_visualizer(\n",
    "        kmeans_clusters[i],\n",
    "        X=df_feature,\n",
    "        ax=ax,\n",
    "        is_fitted=False,\n",
    "        show=False,\n",
    "        colors=sns.color_palette(\"tab10\"),\n",
    "    )\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp = PCA(n_components=2)\n",
    "decomp_components = decomp.fit_transform(df_feature)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "sns.scatterplot(\n",
    "    x=decomp_components[:, 0],\n",
    "    y=decomp_components[:, 1],\n",
    "    hue=kmeans_clusters[4].predict(df_feature),\n",
    "    palette=sns.color_palette(\"tab10\", 6),\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xticklabels([\"\"])\n",
    "ax.set_yticklabels([\"\"])\n",
    "plt.suptitle(\"clusters visualised with PCA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp_umap = umap.UMAP(\n",
    "    n_components=2, min_dist=0.5, n_neighbors=12, n_jobs=1, random_state=91\n",
    ")\n",
    "decomp_components_umap = decomp_umap.fit_transform(df_feature)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=decomp_components_umap[:, 0],\n",
    "    y=decomp_components_umap[:, 1],\n",
    "    hue=kmeans_clusters[4].predict(df_feature),\n",
    "    palette=sns.color_palette(\"tab10\", 6),\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xticklabels([\"\"])\n",
    "ax.set_yticklabels([\"\"])\n",
    "plt.suptitle(\"clusters visualised with UMAP\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Evaluation\n",
    "\n",
    "Analyze each customer group's traits, like average age or buying habits. Use metrics like Silhouette Score or Dunn Index to assess clustering quality, evaluating cluster cohesion and separation. A successful clustering result scores well on these metrics and provides actionable business insights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = df_feature.assign(cluster=kmeans_clusters[4].predict(df_feature))\n",
    "df_mall_cluster = df_mall.assign(cluster=kmeans_clusters[4].predict(df_feature)).drop(\n",
    "    columns=[\"id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "df_all = pd.concat([df_mall.drop(columns=[\"id\"]), df_cluster], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouper = df_mall_cluster.groupby(\"cluster\", as_index=False)\n",
    "df_cluster_agg = grouper.mean().round(2)\n",
    "df_cluster_agg = df_cluster_agg.assign(\n",
    "    count=grouper.count()[\"age\"], age=(df_cluster_agg[\"age\"].astype(\"int\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(\n",
    "    df_mall_cluster,\n",
    "    y=\"cluster\",\n",
    "    x=\"age\",\n",
    "    orient=\"h\",\n",
    "    hue=\"cluster\",\n",
    "    palette=sns.color_palette(\"tab10\", 6),\n",
    ")\n",
    "\n",
    "plt.title(\"Age of each customer segment\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(\n",
    "    df_cluster,\n",
    "    x=\"cluster\",\n",
    "    hue=\"gender\",\n",
    "    stat=\"proportion\",\n",
    "    palette=sns.color_palette(\"tab10\", 2),\n",
    ")\n",
    "plt.legend(\n",
    "    [\n",
    "        \"female\",\n",
    "        \"male\",\n",
    "    ]\n",
    ")\n",
    "plt.title(\"gender ratio between the customer segments\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.2\n",
    "mean_gender = df_mall[\"gender\"].mean()\n",
    "l_mean_gender, u_mean_gender = mean_gender * (1 - a), mean_gender * (1 + a)\n",
    "\n",
    "# define a mostly gender column\n",
    "# determine which cluster falls outside of the bounds\n",
    "df_gender = df_cluster_agg[[\"cluster\", \"gender\"]].assign(type_gender=\"neutral\")\n",
    "df_gender.loc[df_gender[\"gender\"].gt(u_mean_gender), \"type_gender\"] = \"mostly men\"\n",
    "df_gender.loc[df_gender[\"gender\"].lt(l_mean_gender), \"type_gender\"] = \"mostly female\"\n",
    "df_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=FIGSIZE)\n",
    "\n",
    "curr_ax = ax\n",
    "_ = sns.scatterplot(\n",
    "    data=df_cluster_agg,\n",
    "    x=\"income\",\n",
    "    y=\"spending\",\n",
    "    hue=\"cluster\",\n",
    "    palette=sns.color_palette(\"tab10\", 6),\n",
    "    s=150,\n",
    "    ax=curr_ax,\n",
    ")\n",
    "\n",
    "xlim0, xlim1 = ax.get_xlim()\n",
    "ylim0, ylim1 = ax.get_ylim()\n",
    "\n",
    "plt.vlines(\n",
    "    df_mall_cluster[\"income\"].median(), ylim0, ylim1, color=\"grey\", linestyles=\"--\"\n",
    ")\n",
    "plt.hlines(\n",
    "    df_mall_cluster[\"spending\"].median(),\n",
    "    xlim0,\n",
    "    xlim1,\n",
    "    color=\"grey\",\n",
    "    linestyles=\"--\",\n",
    ")\n",
    "plt.suptitle(\"Income vs. Spending\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights and Business Applications\n",
    "\n",
    "Explain how the results could be used to tailor marketing strategies towards each segment for improved customer engagement and retention.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\\n\",\"\\n\",\"In this initial stage, the goal is to prepare the data for analysis. This involves cleaning the data by removing or filling in missing values, which could be done through various strategies like dropping the missing rows, filling them with mean/median/mode, or using a prediction model. It's also crucial to handle outliers and potentially normalize features if they're on different scales. This stage might also involve dealing with categorical variables using encoding techniques. Effective preprocessing is crucial for reliable results in the subsequent stages.\\n\",\"\\n\",\"\\n\",\"the owner of the mall has provide the following [dataset](https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python)\\n\",\"\\n\",\"| Field                  | Description                                                               |\\n\",\"| ---------------------- | ------------------------------------------------------------------------- |\\n\",\"| CustomerID             | Unique ID assigned to the customer                                        |\\n\",\"| Gender                 | Gender of the customer                                                    |\\n\",\"| Age                    | Age of the customer                                                       |\\n\",\"| Annual Income (k$)     | Annual income of the customer                                             |\\n\",\"| Spending Score (1-100) | Score assigned by the mall based on customer behavior and spending nature |\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "### creating the front image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "import gif  # noqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the cluster labels to the dataframe\n",
    "df_mall_cluster_centroid = df_mall_cluster.merge(\n",
    "    df_cluster_agg.drop(columns=[\"count\"]), on=\"cluster\", suffixes=(\"\", \"_cluster\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blend(df_in: pd.DataFrame, col1: str, steps: int):\n",
    "    \"\"\"\n",
    "    Applies a function that generates a linear sequence between the value of\n",
    "    a specified column and the corresponding cluster value in each row of the dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_in : pd.DataFrame\n",
    "        Input dataframe with at least two columns: one specified by `col1` and another with `col1` suffix '_cluster'.\n",
    "    col1 : str\n",
    "        The name of the column in the dataframe from which to start the linear sequence.\n",
    "    steps : int\n",
    "        The number of steps in the linear sequence.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A dataframe with each cell containing a linear sequence between the corresponding cell in `col1` and `col1_cluster`.\n",
    "\n",
    "    \"\"\"\n",
    "    return df_in.apply(\n",
    "        lambda row: np.linspace(row[col1], row[f\"{col1}_cluster\"], steps), axis=1\n",
    "    )\n",
    "\n",
    "\n",
    "# add the blend columns to the three variables of interest\n",
    "df_mall_cluster_centroid = df_mall_cluster_centroid.assign(\n",
    "    spending_blend=create_blend(df_mall_cluster_centroid, \"spending\", 50),\n",
    "    age_blend=create_blend(df_mall_cluster_centroid, \"age\", 50),\n",
    "    income_blend=create_blend(df_mall_cluster_centroid, \"income\", 50),\n",
    ")\n",
    "df_mall_cluster_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=FIGSIZE)\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=df_mall_cluster_centroid[\"spending_blend\"].apply(lambda row: row[0]),\n",
    "    y=df_mall_cluster_centroid[\"age_blend\"].apply(lambda row: row[0]),\n",
    "    hue=df_mall_cluster_centroid[\"cluster\"],\n",
    "    palette=sns.color_palette(\"tab10\", 6),\n",
    "    s=200,\n",
    "    alpha=0.7,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "xlim_begin, ylim_begin = ax.get_xlim(), ax.get_ylim()\n",
    "\n",
    "###\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=FIGSIZE)\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=df_mall_cluster_centroid[\"spending_blend\"].apply(lambda row: row[-1]),\n",
    "    y=df_mall_cluster_centroid[\"age_blend\"].apply(lambda row: row[-1]),\n",
    "    hue=df_mall_cluster_centroid[\"cluster\"],\n",
    "    palette=sns.color_palette(\"tab10\", 6),\n",
    "    s=200,\n",
    "    alpha=0.7,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "xlim_end, ylim_end = ax.get_xlim(), ax.get_ylim()\n",
    "\n",
    "zoom_factor = 0.1\n",
    "# get the global axes limits\n",
    "overal_xlim = (\n",
    "    min(xlim_begin[0], xlim_end[0]) * (1 - zoom_factor),\n",
    "    max(xlim_begin[1], xlim_end[1]) * (1 + zoom_factor),\n",
    ")\n",
    "overal_ylim = (\n",
    "    min(ylim_begin[0], ylim_end[0]) * (1 - zoom_factor),\n",
    "    max(ylim_begin[1], ylim_end[1]) * (1 + zoom_factor),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "\n",
    "\n",
    "@gif.frame\n",
    "def plot_step(i, overal_xlim, overal_ylim):\n",
    "    _, ax = plt.subplots(1, 1, figsize=FIGSIZE)\n",
    "\n",
    "    curr_ax = ax\n",
    "    sns.scatterplot(\n",
    "        x=df_mall_cluster_centroid[\"spending_blend\"].apply(lambda row: row[i]),\n",
    "        y=df_mall_cluster_centroid[\"age_blend\"].apply(lambda row: row[i]),\n",
    "        hue=df_mall_cluster_centroid[\"cluster\"],\n",
    "        palette=sns.color_palette(\"tab10\", 6),\n",
    "        s=200,\n",
    "        alpha=0.7,\n",
    "        ax=curr_ax,\n",
    "    )\n",
    "    # set the overal axes\n",
    "    ax.set_xlim(overal_xlim), ax.set_ylim(overal_ylim)\n",
    "\n",
    "    # remove the ticks and lables from the axes\n",
    "    xticks = ax.get_xticks()\n",
    "    ax.set_xticks(xticks, labels=[])\n",
    "    ax.set_xlabel(\"\")\n",
    "\n",
    "    yticks = ax.get_yticks()\n",
    "    ax.set_yticks(yticks, labels=[])\n",
    "    ax.set_ylabel(\"\")\n",
    "    plt.legend(\"\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_frames = 10\n",
    "num_of_steps = len(df_mall_cluster_centroid[\"spending_blend\"][0])\n",
    "# create the animation\n",
    "gif_frames = [plot_step(i, overal_xlim, overal_ylim) for i in range(num_of_steps)]\n",
    "\n",
    "# freeze on the bounce point\n",
    "gif_frames.extend([gif_frames[-1] for _ in range(freeze_frames // 6)])\n",
    "\n",
    "# add the the original series in reverse\n",
    "gif_frames.extend(gif_frames[::-1])\n",
    "\n",
    "\n",
    "gif.save(gif_frames, \"artifacts/clumper.gif\", duration=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
