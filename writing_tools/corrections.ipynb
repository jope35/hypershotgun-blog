{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import ollama\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../posts/cluster/cluster_reflect.ipynb\") as file:\n",
    "    notebook = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Your job: \\\n",
    "- Improve grammar and language \\\n",
    "- fix errors \\\n",
    "- cut the clutter \\\n",
    "- but keep tone and voice \\\n",
    "- don't change markdown syntax, \\\n",
    "- rephrase for easier reading \\\n",
    "- limit the use of emoji \\\n",
    "- never cut jokes \\\n",
    "- only return the corrected text, no summaries of changes or list of improvements\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9531c4de0f364b7592cb8398b4607d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "['## TLDR;\\n', '\\n', '- **Unsupervised Learning** -> Clustering algorithms are used for unsupervised learning, ideal for exploratory data analysis.\\n', '- **Grouping Data** -> These algorithms group similar data into clusters based on specific criteria.\\n', \"- **Variety of Applications** -> They're used in diverse fields like customer segmentation, anomaly detection, and more.\\n\", '- **Different Techniques** -> Various types exist, like K-means and DBSCAN, each with unique strengths and suited for specific data types.\\n', '- **Choice of Parameters** -> The selection and tuning of parameters, like the number of clusters, significantly influence the results.\\n', '\\n', 'In the field of machine learning,clustering algorithms play a role in uncovering hidden patterns present in the data. they group together datapoints based on the simalirty of features without the need for labeled data, these groups are refered to as clusters.\\n', 'There are multiple algorithms that can be used to perform cluster analysis.\\n', '\\n', '- centroid based (K-means)\\n', '- connectivity-based aka hierarchical clustering (Agglomerative lcustering)\\n', '- distribution based (Gaussian-mixture modelling)\\n', '- density based (DBSCAN)\\n', '\\n', 'Clustering algorithms have found their place in a diverse range of real-world applications, from customer segmentation in marketing strategies to image segmentation in computer vision, and anomaly detection in cybersecurity for insightful data-driven decision making.\\n', '\\n', 'To demonstrate the workflow, I will use a K-means clustering algorithm to group together similar shoppers at a shopping mall.\\n']\n",
      "------\n",
      "['## Business Problem Introduction\\n', '\\n', 'As the owners of a thriving supermarket mall, you seek a deeper understanding of your customer base. Data points including demographics, spending habits, and loyalty program membership details are at your disposal. Your goal is to identify distinct groups within your customers to tailor marketing initiatives, thereby maximizing the efficiency of your promotional efforts.\\n', '\\n', 'To achieve this, you opt for clustering algorithms to group similar customers based on characteristics and behaviors. By isolating specific segments of your customer base, you aim to tailor marketing strategies to respective subgroups, increasing the likelihood of a successful outcome and resulting in maximizing the bang for your marketing buck.\\n']\n",
      "------\n",
      "['## Data Preprocessing\\n', '\\n', \"In this initial stage, the goal is to prepare the data for analysis. This involves cleaning the data by removing or filling in missing values, which could be done through various strategies like dropping the missing rows, filling them with mean/median/mode, or using a prediction model. It's also crucial to handle outliers and potentially normalize features if they're on different scales. This stage might also involve dealing with categorical variables using encoding techniques. Effective preprocessing is crucial for reliable results in the subsequent stages.\\n\", '\\n', 'the owner of the mall has provide the following [dataset](https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python)\\n', '\\n', '| Field                  | Description                                                               |\\n', '| ---------------------- | ------------------------------------------------------------------------- |\\n', '| CustomerID             | Unique ID assigned to the customer                                        |\\n', '| Gender                 | Gender of the customer                                                    |\\n', '| Age                    | Age of the customer                                                       |\\n', '| Annual Income (k$)     | Annual income of the customer                                             |\\n', '| Spending Score (1-100) | Score assigned by the mall based on customer behavior and spending nature |\\n']\n",
      "------\n",
      "['So, upon taking a look at the dataset, it seems like we\\'ve got a mix of numeric and non-numeric columns. Specifically, the `gender` column is the only non-numeric feature - it\\'s all categorical data, with customers labeled as either \"Male\" or \"Female\". All the other columns - `id`, `age`, `income`, and `spending` - are numeric data types.\\n', '\\n', \"The `id` column looks like it's just a unique identifier for each customer, so we can exclude that one from our feature set for clustering. Makes sense, right?\\n\", '\\n', \"Now, the other features need to be in the same ballpark (i.e., normalized) to work effectively with clustering algorithms. Otherwise, the algorithm will group together instances based on the features with the highest numbers, rather than looking at all the features. That'd be like trying to compare apples and oranges!\\n\", '\\n', 'So, we need to process the `gender` column by encoding those categories as numbers. One common way to do this is to map \"Male\" and \"Female\" to 1 and 0, respectively. Once we\\'ve done that, gender will be represented numerically like the other features.\\n', '\\n', \"In a nutshell, we need to encode the gender categorical data, exclude the customer `id` column, and normalize the remaining columns before we can apply clustering algorithms. Luckily for us, there are no NULL values in the data, so we don't have to worry about dealing with those. Easy peasy!\\n\"]\n",
      "------\n",
      "['I used one-hot encoding to convert the string values of the gender column into numerical values, using the pandas map method in combination with a simple mapping of \"male\" to 1 and \"female\" to 0. This resulted in a new \"gender\" column with 0/1 encoding.\\n', 'The `id` column is dropped from the feature dataframe.\\n']\n"
     ]
    }
   ],
   "source": [
    "for cell in tqdm(notebook[\"cells\"]):\n",
    "    # print(cell[\"cell_type\"])\n",
    "    if cell[\"cell_type\"] == \"markdown\":\n",
    "        print(\"-\" * 6)\n",
    "        print(cell[\"source\"])\n",
    "\n",
    "        response = ollama.generate(\n",
    "            model=\"mistral\",\n",
    "            system=instruction,\n",
    "            prompt=\" \".join(cell[\"source\"]),\n",
    "            keep_alive=\"5m\",\n",
    "        )\n",
    "\n",
    "        cell[\"source\"].append(\"--- \\n \" + response[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../posts/cluster/cluster_reflect.ipynb\", mode=\"w\") as output_file:\n",
    "    json.dump(notebook, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypershotgun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
