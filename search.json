[
  {
    "objectID": "posts/boring_forecast/boring_linear_forecast.html",
    "href": "posts/boring_forecast/boring_linear_forecast.html",
    "title": "Boring linear forecast",
    "section": "",
    "text": "Linear regression on itself is not performant for longer time-scales\nMost systems have some capabilities for linear regression built-in\nAdding dummy variables for datetime features(i.e. months, weekday etc.) adds predictive power"
  },
  {
    "objectID": "posts/boring_forecast/boring_linear_forecast.html#introduction",
    "href": "posts/boring_forecast/boring_linear_forecast.html#introduction",
    "title": "Boring linear forecast",
    "section": "2 Introduction",
    "text": "2 Introduction\nLinear regrerssion is a statistical model that can be used to determine the linear relationship between variables, most of the time this is seen as a beginners model that is not particularly useful, and most of the time it is discarded and replaced by a shiny neural net or a fancy gradient-boosted model.\nthe nice feature of linear regression is that the direction and magnitude of the relationship can be estimated with the help of linear regression. It is used in many fields including but not limited to Economics, Finance, Social science, etc. The popularity of this model is model is likely due to the fact that most systems have built-in functionality that enables the training of linear models, they are also very cheap/fast to train, and one can also determine that the model has optimal parameters. all these features make linear regression an excellent model to start with.\nTo extend the capabilities of the linear model for time series forecasting, dummy variables can be utilized. These dummies can provide additional information about the relationship over time, can help the model to identify seasonality over time and also gauge the effect of one-off events, examples are price reductions or natural disasters.\nFor instance we can create a dummy to identify certain datetime features such as what the month is orwhether a particular day is a weekday or a weekend."
  },
  {
    "objectID": "posts/boring_forecast/boring_linear_forecast.html#imports",
    "href": "posts/boring_forecast/boring_linear_forecast.html#imports",
    "title": "Boring linear forecast",
    "section": "3 Imports",
    "text": "3 Imports\nFirst we import all the libraries, the default data science libs and the linear model and metrics from sklearn.\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler"
  },
  {
    "objectID": "posts/boring_forecast/boring_linear_forecast.html#reading-in-the-data",
    "href": "posts/boring_forecast/boring_linear_forecast.html#reading-in-the-data",
    "title": "Boring linear forecast",
    "section": "4 Reading in the data",
    "text": "4 Reading in the data\nFor this example we will be using a dataset form the prophet package. I have selected this one because in the prophet documentation this dataset is used in the section “Seasonality, Holiday Effects, And Regressors” so it seems fitting to use it, to demonstrate the usefullness of seasonal dummies. The prophet docs describe the dataset in the following way:\n\nAs an example, let’s look at a time series of the log daily page views for the Wikipedia page for Peyton Manning. We scraped this data using the Wikipedia trend package in R. Peyton Manning provides a nice example because it illustrates some of Prophet’s features, like multiple seasonality, changing growth rates, and the ability to model special days (such as Manning’s playoff and superbowl appearances).\n\n\n\nCode\ndf_in = pd.read_csv(\n    \"https://raw.githubusercontent.com/facebook/prophet/main/examples/example_wp_log_peyton_manning.csv\"\n)\ndf_in = df_in.assign(ds=pd.to_datetime(df_in[\"ds\"]))\ndf_in = df_in[(df_in[\"ds\"] > \"2012\")]  # selecting data after 2012\n\n\nlets plot the data over time to see what we visually can extract from the plot.\n\n\nCode\nplt.plot_date(\n    x=df_in[\"ds\"],\n    y=df_in[\"y\"],\n    label=\"input timeseries\",\n    fmt=\"-\",\n)\nplt.tick_params(axis=\"x\", rotation=45)\nplt.ylabel(\"target variable - $y$\")\nplt.title(\"daily visits ot Peyton Manning wiki on a daily basis (log)\")\nplt.show()\n\n\n\n\n\nI have selected data from 2012 onwards, this should be enough to testdrive the seasonal dummies. The first thing that I notice is that there is a dip around month 06 and 07. Most likely the american football (handegg?) season is having its summer break then. Also the same pattern repeats over the years start high then dips and then and high again. so there is some repeating seasonality. Lets continue and train our first models. starting with a simple plain linear regression and then adding in the dummies to see if they improve the performance of the model."
  },
  {
    "objectID": "posts/boring_forecast/boring_linear_forecast.html#train-test-split",
    "href": "posts/boring_forecast/boring_linear_forecast.html#train-test-split",
    "title": "Boring linear forecast",
    "section": "5 Train-test split",
    "text": "5 Train-test split\n\n\nCode\n# train test split\ndf_train = df_in[(df_in[\"ds\"] > \"2012\") & (df_in[\"ds\"] < \"2015\")]\ndf_test = df_in[(df_in[\"ds\"] > \"2015\")]\n\n\nTo gauge the performance of the model the data is split in two parts, the train data 2012 onwards up to 2015 and the test data everything after 2015. The model will only see the train data and is asked to create a prediction for the test data, afterwards we will calcualte the perfomance.\n\n\nCode\nplt.plot_date(\n    x=df_train[\"ds\"],\n    y=df_train[\"y\"],\n    label=\"train\",\n    fmt=\"-\",\n)\nplt.plot_date(\n    x=df_test[\"ds\"],\n    y=df_test[\"y\"],\n    label=\"test\",\n    fmt=\"-\",\n)\nplt.legend(loc=\"upper right\")\nplt.tick_params(axis=\"x\", rotation=45)\nplt.ylabel(\"$y$\")\nplt.title(\"train-test split\")\nplt.show()"
  },
  {
    "objectID": "posts/boring_forecast/boring_linear_forecast.html#setting-up-the-regression",
    "href": "posts/boring_forecast/boring_linear_forecast.html#setting-up-the-regression",
    "title": "Boring linear forecast",
    "section": "6 Setting up the regression",
    "text": "6 Setting up the regression\n\n\nCode\nX_train = df_train[\"ds\"].astype(int).values.reshape(-1, 1)\ny_train = df_train[\"y\"].values\n\nX_test = df_test[\"ds\"].astype(int).values.reshape(-1, 1)\ny_test = df_test[\"y\"].values\n\n\nshaping the data so that we can fit the linear model.\n\n\nCode\n# creating, fit, and inference\nlinear = LinearRegression()\nlinear.fit(X=X_train, y=y_train)\ny_pred = linear.predict(X=X_test)\n\n\nThe model fits super fast\n\n\nCode\nmse = mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nprint(f\"mean squared error = {mse:.3}\")\nprint(f\"mean absolute error = {mae:.3}\")\n\n\nmean squared error = 0.617\nmean absolute error = 0.615\n\n\n\n\nCode\nplt.plot_date(\n    x=df_train[\"ds\"],\n    y=df_train[\"y\"],\n    label=\"train\",\n    fmt=\"-\",\n)\nplt.plot_date(\n    x=df_test[\"ds\"],\n    y=df_test[\"y\"],\n    label=\"test\",\n    fmt=\"-\",\n)\n\nplt.plot_date(\n    x=df_test[\"ds\"],\n    y=y_pred,\n    label=\"prediction\",\n    fmt=\"-\",\n)\n\nplt.legend(loc=\"upper right\")\nplt.tick_params(axis=\"x\", rotation=45)\nplt.ylabel(\"$y$\")\nplt.title(f\"linear regression applied (MSE= {mse:.3}, MAE={mae:.3})\")\nplt.show()\n\n\n\n\n\n\n\nCode\n# creating dummies for the months\ndf_dummies = df_in.assign(\n    month=df_in[\"ds\"].dt.month.astype(\"category\"), ds_int=df_in[\"ds\"].astype(int)\n)\n\nnot_dummy = {\"y\", \"ds\", \"ds_int\"}\nto_dummy = set(df_dummies.columns) - not_dummy\n\ndf_dummies = pd.get_dummies(data=df_dummies, columns=[\"month\"])\nall_features = list(set(df_dummies.columns) - {\"y\", \"ds\"})\n\n# slicing the input in train test\ndf_train_dummies = df_dummies[(df_dummies[\"ds\"] > \"2012\") & (df_dummies[\"ds\"] < \"2015\")]\ndf_test_dummies = df_dummies[(df_dummies[\"ds\"] > \"2015\")]\n\nX_train = df_train_dummies.loc[:, all_features]\ny_train = df_train_dummies[[\"y\"]]\n\nX_test = df_test_dummies.loc[:, all_features]\ny_test = df_test_dummies[[\"y\"]]\n\n\n\n\nCode\ndf_dummies.drop(columns=\"ds_int\").sample(n=5, random_state=1234567)\n\n\n\n\n\n\n  \n    \n      \n      ds\n      y\n      month_1\n      month_2\n      month_3\n      month_4\n      month_5\n      month_6\n      month_7\n      month_8\n      month_9\n      month_10\n      month_11\n      month_12\n    \n  \n  \n    \n      1538\n      2012-04-18\n      8.335431\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      1647\n      2012-08-06\n      8.144389\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n    \n    \n      2559\n      2015-02-08\n      7.812783\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      1904\n      2013-04-20\n      7.311886\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      2796\n      2015-10-03\n      7.459915\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n    \n  \n\n\n\n\n\n\nCode\n# create the pipeline\npipeline = make_pipeline(StandardScaler(), LinearRegression())\npipeline.fit(X=X_train, y=y_train)\ny_pred_dummies = pipeline.predict(X=X_test)\n\n\n\n\nCode\nmse_dummies = mean_squared_error(y_test, y_pred_dummies)\nmae_dummies = mean_absolute_error(y_test, y_pred_dummies)\nprint(f\"mean squared error = {mse_dummies:.3}\")\nprint(f\"mean absolute error = {mae_dummies:.3}\")\n\n\nmean squared error = 0.326\nmean absolute error = 0.397\n\n\n\n\nCode\nplt.plot_date(\n    x=df_train[\"ds\"],\n    y=df_train[\"y\"],\n    label=\"train\",\n    fmt=\"-\",\n)\nplt.plot_date(\n    x=df_test[\"ds\"],\n    y=df_test[\"y\"],\n    label=\"test\",\n    fmt=\"-\",\n)\n\nplt.plot_date(\n    x=df_test[\"ds\"],\n    y=y_pred_dummies,\n    label=\"prediction /w dummies\",\n    fmt=\"-\",\n)\n\n\nplt.legend(loc=\"upper right\")\nplt.tick_params(axis=\"x\", rotation=45)\nplt.ylabel(\"$y$\")\nplt.title(\n    f\"linear regression /w dummies applied (mse= {mse_dummies:.3}, mae={mae_dummies:.3})\"\n)\nplt.show()"
  },
  {
    "objectID": "posts/boring_forecast/boring_linear_forecast.html#inspecting-the-seasonality",
    "href": "posts/boring_forecast/boring_linear_forecast.html#inspecting-the-seasonality",
    "title": "Boring linear forecast",
    "section": "7 Inspecting the seasonality",
    "text": "7 Inspecting the seasonality\n\n\nCode\n# pull coefs into a seperate df, to plot the influence of time\nlin_reg_coefs = (\n    pd.DataFrame(data=pipeline[\"linearregression\"].coef_, columns=X_train.columns)\n    .T.reset_index()\n    .rename(columns={\"index\": \"month\", 0: \"coefficient\"})\n)\n# exclude the time col\nlin_reg_coefs = lin_reg_coefs[lin_reg_coefs[\"month\"] != \"ds_int\"]\n\n# centering and scaling\nlin_reg_coefs[\"coefficient\"] = (\n    lin_reg_coefs[\"coefficient\"] - lin_reg_coefs[\"coefficient\"].mean()\n) / lin_reg_coefs[\"coefficient\"].mean()\n\n\n\n\nCode\nchart = sns.barplot(\n    data=lin_reg_coefs,\n    x=\"month\",\n    y=\"coefficient\",\n    color=sns.color_palette()[0],\n    order=[\n        \"month_1\",\n        \"month_2\",\n        \"month_3\",\n        \"month_4\",\n        \"month_5\",\n        \"month_6\",\n        \"month_7\",\n        \"month_8\",\n        \"month_9\",\n        \"month_10\",\n        \"month_11\",\n        \"month_12\",\n    ],\n)\nplt.tick_params(axis=\"x\", rotation=45)\nplt.ylabel(\"\")\nplt.title(\"yearly seasonality\")\nplt.show()\n\n\n\n\n\nseasonality over the months aka yearly seasonality"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "🤖 About",
    "section": "",
    "text": "Machine Learning Scientist 🤖\nloves to puzzle 🧩\nAmsterdam area 🇳🇱🇪🇺"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "hyper-shotgun",
    "section": "",
    "text": "Boring linear forecast\n\n\nimproving performance by adding some dummies\n\n\nIn this article we will look at linear regression, and how dummies can be used to extend its capabilities\n\n\n\n\n\n\n2023-03-5\n\n\nJoost de Theije\n\n\n2 min\n\n\n\n\n\n\nNo matching items"
  }
]